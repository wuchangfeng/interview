* CopyonWriteArraylist

    * CopyOnWriteArrayList（写数组的拷贝）是ArrayList的一个线程安全的变体，CopyOnWriteArrayList和CopyOnWriteSet都是线程安全的集合，其中所有可变操作（add、set等等）都是通过对底层数组进行一次新的复制来实现的。
    * 它绝对不会抛出ConcurrentModificationException的异常。因为该列表（CopyOnWriteArrayList）在遍历时将不会被做任何的修改。
    * CopyOnWriteArrayList适合用在“读多，写少”的“并发”应用中，换句话说，它适合使用在读操作远远大于写操作的场景里，比如缓存。它不存在“扩容”的概念，每次写操作（add or remove）都要copy一个副本，在副本的基础上修改后改变array引用，所以称为“CopyOnWrite”，因此在写操作是加锁，并且对整个list的copy操作时相当耗时的，过多的写操作不推荐使用该存储结构。
* HashMap 为什么线程不安全

    * 因为多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap

    * 还有一种说法是在 rehash 的时候导致开销非常大

    * 锁分段技术

    HashTable容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问HashTable的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。

 
* ConcurentHashMap 内存结构

    * ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。

    * 在 ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。 下图是在一个空桶中依次插入 A，B，C 三个 HashEntry 对象后的结构图：


    ![](http://ww1.sinaimg.cn/large/006dXScfly1fdhpejzhusj30hc03bdg0)

    ![](http://ww1.sinaimg.cn/large/006dXScfly1fdhpfcaa8vj30dy06imxm)

    ConcurrentHashMap 在默认并发级别会创建包含 16 个 Segment 对象的数组。每个 Segment 的成员对象 table 包含若干个散列表的桶。每个桶是由 HashEntry 链接起来的一个链表。如果键能均匀散列，每个 Segment 大约守护整个散列表中桶总数的 1/16。

    ![](http://ww1.sinaimg.cn/large/006dXScfly1fdhpg4wt2vj30i70g60tr)

    put 元素进入 ConcurentHashMap 的过程

        * 计算 key 对应的 hash 数值
        * 找到对应的 hash 数值对应的 segment
        * 在 Segment 中执行具体的 put 操作
          这里的加锁操作是针对（键的 hash 值对应的）某个具体的 Segment，锁定的是该 Segment 而不是整个 ConcurrentHashMap。因为插入键 / 值对操作只是在这个 Segment 包含的某个桶中完成，不需要锁定整个ConcurrentHashMap。此时，其他写线程对另外 15 个Segment 的加锁并不会因为当前线程对这个 Segment 的加锁而阻塞。同时，所有读线程几乎不会因本线程的加锁而阻塞（除非读线程刚好读到这个 Segment 中某个 HashEntry 的 value 域的值为 null，此时需要加锁后重新读取该值）。
          相比较于 HashTable 和由同步包装器包装的 HashMap每次只能有一个线程执行读或写操作，ConcurrentHashMap 在并发访问性能上有了质的提高。在理想状态下，ConcurrentHashMap 可以支持 16 个线程执行并发写操作（如果并发级别设置为 16），及任意数量线程的读操作。

        * ConcurrentHashMap 的高并发性主要来自于三个方面：
          用分离锁实现多个线程间的更深层次的共享访问。
          用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。
          通过对同一个 Volatile 变量的写 / 读访问，协调不同线程间读 / 写操作的内存可见性。


* SpareArray 与 ArrayMap 之间的区别

    * 如果key的类型已经确定为int类型，那么使用SparseArray，因为它避免了自动装箱的过程，如果key为long类型，它还提供了一个LongSparseArray来确保key为long类型时的使用

    * 如果key类型为其它的类型，则使用ArrayMap

* String 对象为什么是不可变的？

   底层基于数组实现，而数组的成员变量是 private final
   value是String封装的数组，offset是String在这个value数组中的起始位置，count是String所占的字符的个数

* 什么是深拷贝和浅拷贝

  浅拷贝：使用一个已知实例对新创建实例的成员变量逐个赋值，这个方式被称为浅拷贝。

  深拷贝：当一个类的拷贝构造方法，不仅要复制对象的所有非引用成员变量值，还要为引用类型的成员变量创建新的实例，并且初始化为形式参数实例值。这个方式称为深拷贝


* JAVA中重写equals()方法为什么要重写hashcode()方法?

  > 关于hashCode的作用  　　总的来说，Java中的集合（Collection）有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。         要想保证元素不重复，可两个元素是否重复应该依据什么来判断呢？这就是Object.equals方法了。但是，如果每增加一个元素就检查一 次，那么当元素很多时，后添加到集合中的元素比较的次数就非常多了。也就是说，如果集合中现在已经有1000个元素，那么第1001个元素加入集合时，它 就要调用1000次equals方法。这显然会大大降低效率。         于是，Java采用了哈希表的原理。哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上。这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就一下子能定位到它应该放置的物理位置上。如果这个位置上没有元素，它就可以 直接存储在这个位置上，不用再进行任何比较了；如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了；不相同，也就是发生了Hash key相同导致冲突的情况,那么就在这个Hash key的地方产生一个链表,将所有产生相同hashcode的对象放到这个单链表上去,串在一起。所以这里存在一个冲突解决的问题（很少出现）。这样一来实际调用equals方法的次数就大大降低了，几乎只需要一两次。         **所以，Java对于eqauls方法和hashCode方法是这样规定的：             1、如果两个对象相等，那么它们的hashCode值一定要相等；             2、如果两个对象的hashCode相等，它们并不一定相等(在同一个链表上)。** 

  在上述第二种情况下 ，**若要判断两个对象是否相等，就要去重写 equals() 方法了**。简单来讲 hashCode() 是用来查找用的，equals() 是用来判断两个对象是否相等用的。

* final 关键字作用

  1. final 关键字提高了性能。JVM 和 Java 应用都会缓存 final 变量。
  2. final 变量可以安全的在多线程环境下进行共享，而不需要额外的同步开销。
  3. 使用 final 关键字，JVM 会对方法、变量及类进行优化。

* string 类是不可变的

  1. **只有当字符串是不可变的，字符串池才有可能实现**。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那么String interning将不能实现(译者注：[String interning](http://en.wikipedia.org/wiki/String_interning)是指对不同的字符串仅仅只保存一个，即不会保存多个相同的字符串。)，因为这样的话，如果变量改变了它的值，那么其它指向这个值的变量的值也会一起改变。
  2. **如果字符串是可变的，那么会引起很严重的安全问题**。譬如，数据库的用户名、密码都是以字符串的形式传入来获得数据库的连接，或者在socket编程中，主机名和端口都是以字符串的形式传入。因为字符串是不可变的，所以它的值是不可改变的，否则黑客们可以钻到空子，改变字符串指向的对象的值，造成安全漏洞。
  3. **因为字符串是不可变的，所以是多线程安全的**，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。字符串自己便是线程安全的。
  4. 类加载器要用到字符串，不可变性提供了安全性，以便正确的类被加载。譬如你想加载java.sql.Connection类，而这个值被改成了myhacked.Connection，那么会对你的数据库造成不可知的破坏。
  5. **因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键**，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。

- Java 中内部类为什么可以访问外部类[主要 java 的内部类持有外部类的引用]

    *  编译器自动为内部类添加一个成员变量， 这个成员变量的类型和外部类的类型相同， 这个成员变量就是指向外部类对象的引用；

    *  编译器自动为内部类的构造方法添加一个参数， 参数的类型是外部类的类型， 在构造方法内部使用这个参数为1中添加的成员变量赋值；

    *  在调用内部类的构造函数初始化内部类对象时， 会默认传入外部类的引用。


* 什么是volatile？

    * 关键字volatile是Java虚拟机提供的最轻量级的同步机制。当一个变量被定义成volatile之后，具备两种特性：

    * 保证此变量对所有线程的可见性。当一条线程修改了这个变量的值，新值对于其他线程是可以立即得知的,而普通变量做不到这一点。

    * 禁止指令重排序优化。普通变量仅仅能保证在该方法执行过程中，得到正确结果，但是不保证程序代码的执行顺序。

*　为什么基于volatile变量的运算在并发下不一定是安全的？

    volatile变量在各个线程的工作内存，不存在一致性问题（各个线程的工作内存中volatile变量，每次使用前都要刷新到主内存）。但是Java里面的运算并非原子操作，导致volatile变量的运算在并发下一样是不安全的。

* 为什么使用volatile？

    在某些情况下，volatile同步机制的性能要优于锁（synchronized关键字），但是由于虚拟机对锁实行的许多消除和优化，所以并不是很快。volatile变量读操作的性能消耗与普通变量几乎没有差别，但是写操作则可能慢一些，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。 

*　ConcurrentHashMap

    是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。

* Java 注解的作用

    * 标记，用于告诉编译器一些信息
    * 编译时动态处理，如动态生成代码 
    * 运行时动态处理，如得到注解信息


*  有了解什么是IntentService么？

    intentService 是继承自 Service 并处理异步请求的一个类，在 IntentService 内有一个工作线程来处理耗时操作，当任务执行完后，IntentService 会自动停止，不需要我们去手动结束。如果启动 IntentService 多次，那么每一个耗时操作会以工作队列的方式在 IntentService 的 onHandleIntent 回调方法中执行，依次去执行，执行完自动结束。

*  缓存算法的种类

    * LRU即Least RecentlyUsed，近期最少使用算法。

        也就是当内存缓存达到设定的最大值时将内存缓存中近期最少使用的对象移除，有效的避免了OOM的出现。

    * Least Frequently Used（LFU）

        对每个缓存对象计算他们被使用的频率。把最不常用的缓存对象换走。

    * First in First out（FIFO）

    这是一个低负载的算法，并且对缓存对象的管理要求不高。通过一个队列去跟踪所有的缓存对象，最近最常用的缓存对象放在后面，而更早的缓存对象放在前面，当缓存容量满时，排在前面的缓存对象会被踢走，然后把新的缓存对象加进去。

* Java 如何进行 GC ，判断对象回收的条件是什么

    JVM进行次GC的频率很高,但因为这种GC占用时间极短,所以对系统产生的影响不大。更值得关注的是主GC的触发条件,因为它对系统影响很明显。总的来说,有两个条件会触发主GC:（1）当应用程序空闲时,即没有应用线程在运行时,GC会被调用。因为GC在优先级最低的线程中进行,所以当应用忙时,GC线程就不会被调用,但以下条件除外。
    （2）Java堆内存不足时,GC会被调用。当应用线程在运行,并在运行过程中创建新对象,若这时内存空间不足,JVM就会强制地调用GC线程,以便回收内存用于新的分配。若GC一次之后仍不能满足内存分配的要求,JVM会再进行两次GC作进一步的尝试,若仍无法满足要求,则 JVM将报“out of memory”的错误,Java。由于是否进行主GC由JVM根据系统环境决定,而系统环境在不断的变化当中,所以主GC的运行具有不确定性,无法预计它何时必然出现,但可以确定的是对一个长期运行的应用来说,其主GC是反复进行的。

* 垃圾对象的判定即什么时候进行回收？

    * 引用计数分析算法
    * 可达性算法
    * 对象标记的死亡过程
    * 正确理解引用

* 如何进行垃圾的回收？

    * 标记-清除算法[先标记出所有要回收的对象，标记完成之后统一回收]

      * 标记和清除过程效率都不高
      * 标记清除之后容易产生空间碎片

    * 复制算法[将可用的内存按容量分为大小相等的两块，每次只使用其中的一块。当这一块用完了

      就将存活着的对象复制到另一块上面，然后再把已经使用过的内存一次清理掉]

      * 简单，不用考虑内存碎片
      * 内存缩小为原来的一半，在对象存活率较高时候，需要多次复制，导致效率不高

    * 标记-整理算法[让所有的存活对象向一端移动，然后直接清理掉边界以外的内存]

    * 分代收集算法[将 java 堆分为新生代和老年带，根据各个年代的特点进行设计合适的算法]


* java 的类加载机制

      双亲委派模型（Parents Delegation Model）要求除了顶层的启动类加载器外，其余加载器
      都应当有自己的父类加载器。**类加载器之间的父子关系，通过组合关系复用。**
      工作过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有到父加载器反馈自己无法完成这个加载请求（它的搜索范围没有找到所需的类）时，子加载器才会尝试自己去加载。 Java类随着它的类加载器一起具备了一种带优先级的层次关系。比如java.lang.Object，它存放在rt.jar中，无论哪个类加载器要加载这个类，最终都是委派给启动类加载器进行加载，因此Object类在程序的各个类加载器环境中，都是同一个类。
      如果没有使用双亲委派模型，让各个类加载器自己去加载，那么Java类型体系中最基础的行为也得不到保障，应用程序会变得一片混乱。

*  运行时的数据区域包括哪些

    * 程序计数器(线程私有)
    * Java 虚拟机栈(线程私有)
    * 本地方法栈(线程私有)
    * java 堆(线程共享)
    * 方法区(线程共享)
    * 运行时常量池


* 存泄露的原因是什么？

    内部类为什么会持有外部类的引用.内部类在构建时候，产生了 外部类名.this 的对象，从而导致依赖外部类。下面的实例是静态内部类和弱引用解决 handler 引起的内存泄漏。

    ``` java
    private static class MyHandler extends Handler {
              private final WeakReference<SampleActivity> mActivity;

              public MyHandler(SampleActivity activity) {
                  mActivity = new WeakReference<SampleActivity>(activity);
              }

              @Override
              public void handleMessage(Message msg) {
                  SampleActivity activity = mActivity.get();
                  if (activity != null) {
                      // ...
                  }
              }
          }

          private final MyHandler mHandler = new MyHandler(this);
    ```

* 如何实现一个线程池（线程池原理），优点是什么？

    1. 线程池管理器（ThreadPoolManager）:用于创建并管理线程池
    2. 工作线程（WorkThread）: 线程池中线程
    3. 任务接口（Task）:每个任务必须实现的接口，以供工作线程调度任务的执行。
    4. 任务队列:用于存放没有处理的任务。提供一种缓冲机制。


*  作用在静态方法上的同步锁和作用在非静态方法上的同步锁有什么区别

    * **所有的非静态同步方法用的都是同一把锁——实例对象本身**，也就是说如果一个实例对象的非静态同步方法获取锁后，该实例对象的其他非静态同步方法必须等待获取锁的方法释放锁后才能获取锁，可是别的实例对象的非静态同步方法因为跟该实例对象的非静态同步方法用的是不同的锁，所以毋须等待该实例对象已获取锁的非静态同步方法释放锁就可以获取他们自己的锁。

    * **而所有的静态同步方法用的也是同一把锁——类对象本身**，这两把锁是两个不同的对象，所以静态同步方法与非静态同步方法之间是不会有竞态条件的。但是一旦一个静态同步方法获取锁后，其他的静态同步方法都必须等待该方法释放锁后才能获取锁，而不管是同一个实例对象的静态同步方法之间，还是不同的实例对象的静态同步方法之间，只要它们同一个类的实例对象！

*  七种单列模式 http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/

    一般来说，单例模式有五种写法：懒汉、饿汉、双重检验锁、静态内部类、枚举。下面这种是静态内部类机制。这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。

    ```java
    public class Singleton {  
        private static class SingletonHolder {  
            private static final Singleton INSTANCE = new Singleton();  
        }  
        private Singleton (){}  
        public static final Singleton getInstance() {  
            return SingletonHolder.INSTANCE; 
         }  
        }

    // 双重锁模式
    public class Singleton {
        private volatile static Singleton instance; //声明成 volatile
        private Singleton (){}

     public static Singleton getSingleton() {
        if (instance == null) {                         
            synchronized (Singleton.class) {
                if (instance == null) {       
                    instance = new Singleton();
                }
            }
        }
        return instance;
        }
    }
    ```


-   Error

    Error 是 Throwable 的子类，用于指示合理的应用程序不应该试图捕获的严重问题。大多数这样的错误都是异常条件。和RuntimeException一样， 编译器也不会检查Error。当资源不足、约束失败、或是其它程序无法继续运行的条件发生时，就产生错误，程序本身无法修复这些错误的。 　

-   Exception

    Exception类及其子类是Throwable的一种形式，它指出了合理的应用程序想要捕获的条件。对于可以恢复的条件使用被检查异常（Exception的子类中除了RuntimeException之外的其它子类），对于程序错误使用运行时异常。

-   static 关键字

    在程序中任何变量或者代码都是在编译时由系统自动分配内存来存储的。static修饰符表示静态的，在类加载时JVM会把它放到方法区，被本类以及本类的所有实例所共用。在编译后所分配的内存会一直存在，直到程序退出内存才会释放这个空间。如果一个被所有实例共用的方法被申明为static，那么就可以节省空间，不用每个实例初始化的时候都被分配到内存。我们比较常见的static修饰是在静态变量和静态方法中。它们可以直接通过类名来访问。


-   Java 中的几种引用类型： 强引用，软引用，弱引用，虚引用

     软引用用来描述一些还有用但是并非必须的对象，在Java中用java.lang.ref.SoftReference类来表示。对于软引用关联着的对象，只有在内存不足的时候JVM才会回收该对象。因此，这一点可以很好地用来解决OOM的问题，并且这个特性很适合用来实现缓存：比如网页缓存、图片缓存等。

     弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。

*    Java 静态方法可以被重写吗？

     如果从重写方法会有什么特点来看，我们是不能重写静态方法的。虽然就算你重写静态方法，编译器也不会报错。也就是说，如果你试图重写静态方法，Java不会阻止你这么做，但你却得不到预期的结果（重写仅对非静态方法有用）。重写指的是根据运行时对象的类型来决定调用哪个方法，而不是根据编译时的类型。让我们猜一猜为什么静态方法是比较特殊的？因为它们是类的方法，所以它们在编译阶段就使用编译出来的类型进行绑定了。使用对象引用来访问静态方法只是Java设计者给程序员的自由。我们应该直接使用类名来访问静态方法，而不要使用对象引用来访问。

*    Java 中的异常

     - 检查性异常：最具代表的检查性异常是用户错误或问题引起的异常，这是程序员无法预见的。例如要打开一个不存在文件时，一个异常就发生了，这些异常在编译时不能被简单地忽略。

     - 运行时异常：运行时异常是可能被程序员避免的异常。与检查性异常相反，运行时异常可以在编译时被忽略。

     - 错误：错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如，当栈溢出时，一个错误就发生了，它们在编译也检查不到的。

     - finally 关键字用来创建在 try 代码块后面执行的代码块。

       无论是否发生异常，finally 代码块中的代码总会被执行。

       在 finally 代码块中，可以运行清理类型等收尾善后性质的语句。

     -  throws 与 throw 之间的区别
       **throws 用于抛出方法层次的异常**， 
       并且直接由些方法调用异常处理类来处理该异常， 
       所以它常用在方法的后面。比如 
       public static void main(String[] args) throws SQLException

       **throw 用于方法块里面的代码**，比throws的层次要低，比如try...catch ....语句块，表示它抛出异常， 
       但它不会处理它， 而是由方法块的throws Exception来调用异常处理类来处理。

       throw用在程序中，明确表示这里抛出一个异常。   
       throws用在方法声明的地方，表示这个方法可能会抛出某异常。

       throw是抛出一个具体的异常类，产生一个异常。
       throws则是在方法名后标出该方法会产生何种异常需要方法的使用者捕获并处理。
